{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VOfuM7cGzfr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOCSx_smIE9x"
   },
   "outputs": [],
   "source": [
    "class AugmentedCIFAR10(torchvision.datasets.CIFAR10):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.augment = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, padding=4), # randomly crops an image to a size of 32x32 pixels, while padding the image with 4 pixels on each side before cropping.\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2) # randomly changes the brightness, contrast, saturation, and hue of an image by up to 20%.\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.train:\n",
    "            img = self.augment(img)\n",
    "        img = np.array(img)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yf_pDnHnJVN6",
    "outputId": "2884dfc5-b332-425f-a3d3-ec2524f00452"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Converts an image to a tensor, which can then be used as input to a PyTorch model.\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes an image by subtracting the mean of (0.5, 0.5, 0.5) and dividing by the standard deviation of (0.5, 0.5, 0.5). After normalizing, the pixel values will range from -1 to 1.\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "trainset = AugmentedCIFAR10(root='./data', train=True,\n",
    "                            download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True)#, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False)#, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog',\n",
    "           'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XdEtOB0KNOt"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # `3` is the number of input channels for a colored image.\n",
    "        # `6` is the number of output channels (neurons). It is a hyperparameter.\n",
    "        # `5` is the kernel size (5x5 pixels).\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # `2` is the kernel size (2x2 pixels) of the pooling operation.\n",
    "        # `2` is the stride of the pooling operation.\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # `6` is the number of input channels which must be equal to the number of output channels in the previous layer.\n",
    "        # `16` is the number of output channels (neurons). It is a hyperparameter.\n",
    "        # `5` is the kernel size (5x5 pixels).\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # `16*5*5` is the number of input channels which must be equal to the number of output channels in the previous layer. We have 16 neurons in the previous channel each being 5x5. Therefore, the total would be 16*5*5.\n",
    "        # `120` is the number of output channels (neurons). It is a hyperparameter.\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # `120` is the number of input channels which must be equal to the number of output channels in the previous layer.\n",
    "        # `84` is the number of output channels (neurons). It is a hyperparameter.\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # `84` is the number of input channels which must be equal to the number of output channels in the previous layer.\n",
    "        # `10` is the number of output channels (neurons). In classification problems, it must be equal to the number of possible classes.\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # `relu` is the activation function.\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        # `view` is used to reshape the tensor. It is to prepare the data before feeding it to a fully connected layar. `Flatten` can also be used for the same prupose.\n",
    "        # `-1` tells PyTorch to automatically infer the first dimension of the tensor which is the number of batch size used in the training parameters.\n",
    "        # `16*5*5` is the number of input channels which must be equal to the number of output channels in the previous layer. We have 16 neurons in the previous channel each being 5x5. Therefore, the total would be 16*5*5.\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmHRtz-hMZjc"
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Initialize TensorBoard\n",
    "writer = SummaryWriter('runs/cifar10_experiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1sUPc7lMlDE",
    "outputId": "f6961f82-45b1-42bb-c5df-90d36ef304aa"
   },
   "outputs": [],
   "source": [
    "# `2` is the number of training iterations. It is a hyperparameter.\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        # It is used to zero out the gradients of all the parameters in the optimizer.\n",
    "        # This is to avoid gradient accumulation from previous iterations which can lead to inaccurate updates to the model parameters.\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}')\n",
    "            writer.add_scalar('training loss',\n",
    "                              running_loss / 2000,\n",
    "                              epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ib-Czbu6a47"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "# Write the accuracy to TensorBoard\n",
    "writer.add_scalar('accuracy',\n",
    "                   100 * correct / total,\n",
    "                   epoch * len(trainloader) + i)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/cifar10_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GuMd6_iwRb33",
    "outputId": "2fc78835-6ee9-4926-ba1b-fc4f4df19ea5"
   },
   "outputs": [],
   "source": [
    "def imshow(img, title=None):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some of the predictions\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Print images with predictions\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "\n",
    "# Show images with predictions\n",
    "for i in range(4):\n",
    "    imshow(images[i], f'GroundTruth: {classes[labels[i]]} \\nPredicted: {classes[predicted[i]]}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
