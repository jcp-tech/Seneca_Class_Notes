{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Training a Simple Neural Network with GPU\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, you will create, train, and evaluate a simple neural network using both TensorFlow and PyTorch. The objective is to ensure you are comfortable with setting up a neural network and utilizing GPU acceleration for training. \n",
    "\n",
    "The code for this assignment will mirror that of Lab 1, but you will need to complete some items, and make some changes.  You will use the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) for this project.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Set up TensorFlow and PyTorch environments.\n",
    "2. Verify GPU availability.\n",
    "3. Implement a simple neural network in TensorFlow and PyTorch.\n",
    "4. Train and evaluate the models.\n",
    "5. Answer assessment questions.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the steps below to complete the project. Ensure that you use a GPU to train your models.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Set Up Your Environment\n",
    "\n",
    "First, install the necessary libraries. Run the following cell to install TensorFlow and PyTorch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide snapshots from your environment showing:\n",
    "1) You are using a virtual environment\n",
    "2) You have installed `TensorFlow` and `PyTorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 2: Verify GPU Availability\n",
    "Check if TensorFlow and PyTorch can detect the GPU.\n",
    "\n",
    "Run the following two code blocks and show the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NVIDIA GPU Info ===\n",
      "Fri Jun  6 22:30:00 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti     Off |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   42C    P8              1W /   80W |    4772MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1190      G   /usr/lib/xorg/Xorg                       53MiB |\n",
      "|    0   N/A  N/A            4649      C   ..._Class_Notes/.venv/bin/python       4706MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "=== OS Information ===\n",
      "PRETTY_NAME=\"Ubuntu 20.04.6 LTS\"\n",
      "\n",
      "=== Python Version ===\n",
      "Python 3.10.17\n"
     ]
    }
   ],
   "source": [
    "# GPU Info\n",
    "print(\"\\n=== NVIDIA GPU Info ===\")\n",
    "!nvidia-smi\n",
    "\n",
    "# # CUDA Version\n",
    "# print(\"\\n=== CUDA Version ===\")\n",
    "# !nvcc --version\n",
    "\n",
    "# # cuDNN Version\n",
    "# print(\"\\n=== cuDNN Version ===\")\n",
    "# !cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\n",
    "\n",
    "# # CPU Info\n",
    "# print(\"\\n=== CPU Model ===\")\n",
    "# !lscpu | grep \"Model name\"\n",
    "\n",
    "# # RAM Info\n",
    "# print(\"\\n=== RAM Info ===\")\n",
    "# !free -h | grep Mem\n",
    "\n",
    "# OS Info\n",
    "print(\"\\n=== OS Information ===\")\n",
    "!cat /etc/os-release | grep PRETTY_NAME\n",
    "\n",
    "# Python Version\n",
    "print(\"\\n=== Python Version ===\")\n",
    "!python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "GPU is available for TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU is available for TensorFlow!\")\n",
    "else:\n",
    "    print(\"No GPU found for TensorFlow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "GPU is available for PyTorch!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available for PyTorch!\")\n",
    "elif torch.mps.is_available():\n",
    "    print(\"MPS (Apple Silicon GPU support) is available for PyTorch!\")\n",
    "else:\n",
    "    print(\"No GPU found for PyTorch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 3: Implement and Train a Simple Neural Network\n",
    "#### TensorFlow Implementation\n",
    "1. Load and preprocess the Fashion MNIST dataset.\n",
    "2. Define the neural network model.  Departing from the example in class, use 2 hidden layers, each with 64 units and relu activation functions, densely connected.\n",
    "3. Compile the model.\n",
    "4. Train the model using the GPU.  Use a batch size of 64, and run 6 epochs.\n",
    "5. Evaluate the model.\n",
    "\n",
    "You need to complete and run the code. Show the complete output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5340 - accuracy: 0.8119 - val_loss: 0.4156 - val_accuracy: 0.8520\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3896 - accuracy: 0.8582 - val_loss: 0.3841 - val_accuracy: 0.8612\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3524 - accuracy: 0.8706 - val_loss: 0.3604 - val_accuracy: 0.8702\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3297 - accuracy: 0.8776 - val_loss: 0.3503 - val_accuracy: 0.8687\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3085 - accuracy: 0.8854 - val_loss: 0.3526 - val_accuracy: 0.8728\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8624\n",
      "Test accuracy: 0.8624\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "fashion_mnist_data = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist_data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# with tf.device('/GPU:0'):\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Implementation\n",
    "1. Load and preprocess the Fashion MNIST dataset.  Set batch size to 64.\n",
    "2. Define the neural network model.  Departing from the example in class, use 2 hidden layers, each with 64 units and relu activation functions, densely connected.  \n",
    "4. Define loss function and optimizer.\n",
    "5. Train the model using the GPU.  Run 6 epochs.\n",
    "6. Evaluate the model.\n",
    "\n",
    "You need to complete and run the code. Show the complete output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Loss: 0.3309\n",
      "Epoch [2/6], Loss: 0.5422\n",
      "Epoch [3/6], Loss: 0.3912\n",
      "Epoch [4/6], Loss: 0.4251\n",
      "Epoch [5/6], Loss: 0.3989\n",
      "Epoch [6/6], Loss: 0.3248\n",
      "Test Accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.hidden1 = nn.Linear(28*28, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.output = nn.Linear(64, 10)  # for 10 classes, e.g., MNIST\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda'\n",
    "elif torch.mps.is_available():\n",
    "    dev = 'mps'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questions\n",
    "Answer the following questions in detail.\n",
    "\n",
    "1. What is the purpose of normalizing the input data in both TensorFlow and PyTorch implementations?\n",
    "2. Explain the role of the activation function relu in the neural network.\n",
    "3. Why is it important to use GPU for training neural networks?\n",
    "4. Compare the training time and accuracy of the TensorFlow and PyTorch models. Which one performed better and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1\n",
    "\n",
    "Normalization is the process of scaling input data so that its values lie within a specific range (commonly `[-1, 1]` or `[0, 1]`).\n",
    "\n",
    "In both TensorFlow and PyTorch, we normalize FashionMNIST images—originally with pixel values ranging from 0 to 255—by dividing by 255. This scales the values to the range `[0, 1]`.\n",
    "\n",
    "**Purpose:**\n",
    "- Faster convergence during training  \n",
    "- Improved generalization of the model  \n",
    "- Ensures input features have similar scales, helping the network learn more effectively\n",
    "\n",
    "\n",
    "## Answer 2\n",
    "\n",
    "**ReLU** (Rectified Linear Unit) introduces non-linearity into the neural network, allowing it to learn complex patterns.\n",
    "\n",
    "**Benefits:**\n",
    "- Enables learning of non-linear relationships  \n",
    "- Simple and efficient to compute  \n",
    "- Reduces vanishing gradient issues (positive inputs have gradient = 1)  \n",
    "- Promotes sparse activation (sets negatives to zero), improving generalization\n",
    "\n",
    "\n",
    "## Answer 3\n",
    "\n",
    "**GPU Importance:**\n",
    "- Enables massive parallel processing for matrix and tensor operations  \n",
    "- ALOT faster than CPU for large models  \n",
    "- Saves time and energy during training  \n",
    "- Makes training large models feasible and scalable\n",
    "\n",
    "**Note:** For small tasks, CPUs may suffice, but GPUs are essential for complex models or big datasets.\n",
    "\n",
    "\n",
    "## Answer 4\n",
    "\n",
    "**Results Summary:**\n",
    "\n",
    "| Framework  | Training Time | Accuracy |\n",
    "|------------|---------------|----------|\n",
    "| TensorFlow | 16.7 sec      | 86.24%   |\n",
    "| PyTorch    | 59.6 sec      | 86.67%   |\n",
    "\n",
    "**Which Performed Better & Why:**\n",
    "\n",
    "- **TensorFlow** trained faster (16.7s vs 59.6s)  \n",
    "- **PyTorch** had slightly higher accuracy (86.67% vs 86.24%)  \n",
    "- Speed difference likely due to TensorFlow's better GPU/data pipeline usage  \n",
    "- Accuracy gap is minor and likely from random variation\n",
    "\n",
    "**Conclusion:**  \n",
    "In this Scenario with my Particular Specifications `TensorFlow` is better for speed; `PyTorch` slightly better in accuracy. Both are suitable for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Submission\n",
    "Submit a link to your completed Jupyter Notebook (e.g., on GitHub (private) or Google Colab) with all the cells executed, and answers to the assessment questions included at the end of the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
