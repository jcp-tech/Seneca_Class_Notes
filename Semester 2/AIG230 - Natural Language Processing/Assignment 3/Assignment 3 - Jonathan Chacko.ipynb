{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24775f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "'''\n",
    "Create a variable words containing a list of words. Experiment with words.sort() and sorted(words) (and perhaps your list itself) until the difference in operation is clear. What is the difference?\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb57553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "'''\n",
    "Load the text from a portion of the 2024 Federal Budget (located at https://budget.canada.ca/2024/report-rapport/chap3-en.html\". Store the plain text (with HTML tags/etc. removed) into a string. Print the first 150 characters of the string.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "'''\n",
    "Use nltk.regexp_tokenize() to tokenize the string you created in Question 2. Use a regexp so that only punctuation characters are tokenized (i.e., your regexp should match any (and only) punctuation). Some notes, tips:\n",
    "\n",
    "Please use the 'verbose' flag in your regexp. Starting your regexp with the verbose flag '(?x)' allows your regexp to be spread over multiple lines (with whitespace ignored), for increased readability. Enclose your regexp in triple quotes (\"\"\").\n",
    "Certain punctuation characters are also operators within the regexp (e.g., the period). You can include these characters as literals by escaping them with a preceding backslash. (E.g., \\. matches a period character, rather than matching any character.)\n",
    "\n",
    "\n",
    "Print the first 20 elements of the resulting string. Also, use FreqDist to count the frequency of each punctuation symbol.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "'''\n",
    "Again, use nltk.regexp_tokenize() to tokenize the string you created in Question 2. This time, use a regexp that will tokenize dollar amounts. More specifically:\n",
    "\n",
    "Dollar amounts will begin with a '$' character.\n",
    "The next 1 to 3 characters will be digits.\n",
    "For larger numbers, the initial digits may be followed by groups consisting of a comma followed by three digits.\n",
    "Finally, there may be a single decimal point followed by an unlimited number of digits.\n",
    "The entire 'numerical' portion of the dollar amount might be followed by the word 'million' or 'billion' (with the first character lower- or upper-case).\n",
    "\n",
    "\n",
    "Some tips:\n",
    "\n",
    "Build your regexp incrementally, getting one portion correct before adding to it!\n",
    "To apply an operator (like * or +) to a sequence of characters, you may use brackets in the expected way. However, as we have discussed in class, brackets also indicate extraction groups. To use brackets to indicate the scope of operators without indicating extraction groups, the opening bracket must be followed by '?:'. E.g., \"(?:abc)* would indicate that the string 'abc' could appear 0 or more times.\n",
    "In your string version of the document, the spaces between the digits and the word million or billion is not a 'normal' space, but rather a unicode non-breaking space (with code \\xa0). It is suggested that you match these using a whitespace character (\\s).\n",
    "\n",
    "\n",
    "Print your entire list of tokens. (It shouldn't be a huge list!)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
